{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b9ae04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niraj_1kwckht\\anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\niraj_1kwckht\\anaconda\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "643699f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\niraj_1kwckht\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cfe89ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a431c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample random text (100 words)\n",
    "random_text = \"\"\"\n",
    "Data processing encompasses a series of operations that convert raw data into structured\n",
    "and organized information. This process begins with data collection, where data is gathered\n",
    "from various sources such as sensors, databases, forms, or external systems. Once collected,\n",
    "the data can be in various formats, including text, numbers, images, or multimedia.\n",
    "The next step in data processing is data cleaning and validation. This involves identifying\n",
    "and correcting errors, inconsistencies, and missing values in the data. Clean and accurate data\n",
    "is essential for reliable analysis and decision-making. Data cleaning often involves techniques\n",
    "like outlier detection and data imputation.\n",
    "After data cleaning, data transformation is performed. This includes tasks like data normalization,\n",
    "aggregation, and summarization. Normalization ensures that data is on a consistent scale, while\n",
    "aggregation and summarization reduce data complexity by generating statistics or aggregating data into meaningful groups.\n",
    "Data processing also includes data integration, where data from multiple sources is combined\n",
    "into a unified dataset. Integration can be challenging due to differences in data structures and\n",
    "formats. Techniques like data mapping and data warehousing are used to facilitate integration.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc3a8c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text into words\n",
    "words = word_tokenize(random_text)\n",
    "\n",
    "# Initialize the NLTK Porter Stemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80442f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\niraj_1kwckht\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Get the English stop words\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Initialize a list to store the preprocessed words\n",
    "preprocessed_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d66216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform text preprocessing\n",
    "for word in words:\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    word = word.lower()\n",
    "    word = word.strip('.,?!-()[]{}\"\\'')\n",
    "\n",
    "    # Check if the word is not a stop word\n",
    "    if word not in stop_words:\n",
    "        # Stem the word\n",
    "        word = stemmer.stem(word)\n",
    "\n",
    "        # Add the preprocessed word to the list\n",
    "        preprocessed_words.append(word)\n",
    "\n",
    "# Join the preprocessed words back into a text\n",
    "preprocessed_text = \" \".join(preprocessed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b12fd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "\n",
      "Data processing encompasses a series of operations that convert raw data into structured\n",
      "and organized information. This process begins with data collection, where data is gathered\n",
      "from various sources such as sensors, databases, forms, or external systems. Once collected,\n",
      "the data can be in various formats, including text, numbers, images, or multimedia.\n",
      "The next step in data processing is data cleaning and validation. This involves identifying\n",
      "and correcting errors, inconsistencies, and missing values in the data. Clean and accurate data\n",
      "is essential for reliable analysis and decision-making. Data cleaning often involves techniques\n",
      "like outlier detection and data imputation.\n",
      "After data cleaning, data transformation is performed. This includes tasks like data normalization,\n",
      "aggregation, and summarization. Normalization ensures that data is on a consistent scale, while\n",
      "aggregation and summarization reduce data complexity by generating statistics or aggregating data into meaningful groups.\n",
      "Data processing also includes data integration, where data from multiple sources is combined\n",
      "into a unified dataset. Integration can be challenging due to differences in data structures and\n",
      "formats. Techniques like data mapping and data warehousing are used to facilitate integration.\n",
      "\n",
      "\n",
      "Preprocessed Text:\n",
      "data process encompass seri oper convert raw data structur organ inform  process begin data collect  data gather variou sourc sensor  databas  form  extern system  collect  data variou format  includ text  number  imag  multimedia  next step data process data clean valid  involv identifi correct error  inconsist  miss valu data  clean accur data essenti reliabl analysi decision-mak  data clean often involv techniqu like outlier detect data imput  data clean  data transform perform  includ task like data normal  aggreg  summar  normal ensur data consist scale  aggreg summar reduc data complex gener statist aggreg data meaning group  data process also includ data integr  data multipl sourc combin unifi dataset  integr challeng due differ data structur format  techniqu like data map data wareh use facilit integr \n"
     ]
    }
   ],
   "source": [
    "# Print the original text and preprocessed text\n",
    "print(\"Original Text:\")\n",
    "print(random_text)\n",
    "print(\"\\nPreprocessed Text:\")\n",
    "print(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b4788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
